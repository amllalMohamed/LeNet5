{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6349ba77-dc29-4e47-8383-b0cba8daea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ll\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9277 - loss: 0.2568\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1134\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0775\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0574\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0443\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0366\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0286\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0232\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0180\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0157\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.9785 - loss: 0.0808\n",
      "\n",
      "Précision sur le jeu de test: 0.9785000085830688\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow et tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Téléchargement du dataset MNIST\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Prétraitement des données\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Construction du modèle\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nPrécision sur le jeu de test: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da32564c-8f45-4af7-9665-38c3e230dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3us/step\n",
      "Epoch 1/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6127 - loss: 0.6880 - val_accuracy: 0.7324 - val_loss: 0.6782\n",
      "Epoch 2/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7334 - loss: 0.6646 - val_accuracy: 0.7662 - val_loss: 0.6432\n",
      "Epoch 3/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7704 - loss: 0.6183 - val_accuracy: 0.7704 - val_loss: 0.5870\n",
      "Epoch 4/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8024 - loss: 0.5536 - val_accuracy: 0.8112 - val_loss: 0.5201\n",
      "Epoch 5/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8299 - loss: 0.4847 - val_accuracy: 0.8268 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8493 - loss: 0.4252 - val_accuracy: 0.8478 - val_loss: 0.4136\n",
      "Epoch 7/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8627 - loss: 0.3793 - val_accuracy: 0.8372 - val_loss: 0.3896\n",
      "Epoch 8/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8734 - loss: 0.3452 - val_accuracy: 0.8610 - val_loss: 0.3569\n",
      "Epoch 9/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8821 - loss: 0.3207 - val_accuracy: 0.8646 - val_loss: 0.3408\n",
      "Epoch 10/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8900 - loss: 0.2983 - val_accuracy: 0.8708 - val_loss: 0.3263\n",
      "Epoch 11/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8953 - loss: 0.2829 - val_accuracy: 0.8724 - val_loss: 0.3207\n",
      "Epoch 12/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9001 - loss: 0.2686 - val_accuracy: 0.8488 - val_loss: 0.3369\n",
      "Epoch 13/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9017 - loss: 0.2587 - val_accuracy: 0.8710 - val_loss: 0.3080\n",
      "Epoch 14/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9094 - loss: 0.2463 - val_accuracy: 0.8800 - val_loss: 0.2963\n",
      "Epoch 15/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9154 - loss: 0.2331 - val_accuracy: 0.8808 - val_loss: 0.2936\n",
      "Epoch 16/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9169 - loss: 0.2267 - val_accuracy: 0.8754 - val_loss: 0.2985\n",
      "Epoch 17/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9162 - loss: 0.2217 - val_accuracy: 0.8878 - val_loss: 0.2864\n",
      "Epoch 18/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9257 - loss: 0.2083 - val_accuracy: 0.8832 - val_loss: 0.2845\n",
      "Epoch 19/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9270 - loss: 0.2022 - val_accuracy: 0.8830 - val_loss: 0.2846\n",
      "Epoch 20/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9298 - loss: 0.1950 - val_accuracy: 0.8788 - val_loss: 0.2911\n",
      "Epoch 21/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9324 - loss: 0.1902 - val_accuracy: 0.8864 - val_loss: 0.2808\n",
      "Epoch 22/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9351 - loss: 0.1824 - val_accuracy: 0.8710 - val_loss: 0.3023\n",
      "Epoch 23/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9337 - loss: 0.1821 - val_accuracy: 0.8874 - val_loss: 0.2811\n",
      "Epoch 24/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9382 - loss: 0.1724 - val_accuracy: 0.8880 - val_loss: 0.2787\n",
      "Epoch 25/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9402 - loss: 0.1679 - val_accuracy: 0.8810 - val_loss: 0.2910\n",
      "Epoch 26/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9428 - loss: 0.1640 - val_accuracy: 0.8882 - val_loss: 0.2830\n",
      "Epoch 27/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9456 - loss: 0.1570 - val_accuracy: 0.8770 - val_loss: 0.2939\n",
      "Epoch 28/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9463 - loss: 0.1528 - val_accuracy: 0.8896 - val_loss: 0.2819\n",
      "Epoch 29/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9505 - loss: 0.1484 - val_accuracy: 0.8870 - val_loss: 0.2854\n",
      "Epoch 30/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9503 - loss: 0.1436 - val_accuracy: 0.8876 - val_loss: 0.2832\n",
      "Epoch 31/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9529 - loss: 0.1410 - val_accuracy: 0.8736 - val_loss: 0.3125\n",
      "Epoch 32/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9477 - loss: 0.1448 - val_accuracy: 0.8782 - val_loss: 0.3024\n",
      "Epoch 33/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9539 - loss: 0.1347 - val_accuracy: 0.8798 - val_loss: 0.3059\n",
      "Epoch 34/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9561 - loss: 0.1309 - val_accuracy: 0.8898 - val_loss: 0.2905\n",
      "Epoch 35/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9593 - loss: 0.1255 - val_accuracy: 0.8892 - val_loss: 0.2929\n",
      "Epoch 36/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9598 - loss: 0.1227 - val_accuracy: 0.8870 - val_loss: 0.2991\n",
      "Epoch 37/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9598 - loss: 0.1227 - val_accuracy: 0.8812 - val_loss: 0.3097\n",
      "Epoch 38/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9564 - loss: 0.1281 - val_accuracy: 0.8900 - val_loss: 0.2989\n",
      "Epoch 39/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9656 - loss: 0.1140 - val_accuracy: 0.8898 - val_loss: 0.3018\n",
      "Epoch 40/40\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9639 - loss: 0.1132 - val_accuracy: 0.8894 - val_loss: 0.3082\n",
      "782/782 - 3s - 4ms/step - accuracy: 0.8752 - loss: 0.3280\n",
      "Précision: 0.8751599788665771\n"
     ]
    }
   ],
   "source": [
    "# Classification de texte avec des critiques de films\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Chargement du dataset IMDb\n",
    "imdb = keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Préparation des données\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "# Vectorisation des données\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "# Construction du modèle\n",
    "vocab_size = 10000\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "results = model.evaluate(test_data, test_labels, verbose=2)\n",
    "print(f'Précision: {results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5468421-d671-4c0f-85a0-86547188c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Création de tensors\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# Création à partir de numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# Opérations sur les tensors\n",
    "x = torch.ones(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "z = torch.add(x, y)\n",
    "\n",
    "# Indexing et slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "\n",
    "# Conversion vers numpy\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "\n",
    "# Déplacement sur GPU\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46a2a53-7267-405f-bd40-a7dad4d5406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement du dataset FashionMNIST\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Affichage d'échantillons\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0367cb4e-bd6d-4314-8e9d-ad6faebc2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Predicted class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Définition du modèle\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = NeuralNetwork()\n",
    "print(model)\n",
    "\n",
    "# Test du modèle\n",
    "X = torch.rand(1, 28, 28)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1cff42-8bb4-4e50-914b-4738e2125be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303633  [    0/60000]\n",
      "loss: 2.286511  [ 6400/60000]\n",
      "loss: 2.275481  [12800/60000]\n",
      "loss: 2.273243  [19200/60000]\n",
      "loss: 2.260459  [25600/60000]\n",
      "loss: 2.223832  [32000/60000]\n",
      "loss: 2.235119  [38400/60000]\n",
      "loss: 2.197005  [44800/60000]\n",
      "loss: 2.195743  [51200/60000]\n",
      "loss: 2.170484  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 2.164775 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.173412  [    0/60000]\n",
      "loss: 2.162867  [ 6400/60000]\n",
      "loss: 2.114901  [12800/60000]\n",
      "loss: 2.134674  [19200/60000]\n",
      "loss: 2.095867  [25600/60000]\n",
      "loss: 2.023427  [32000/60000]\n",
      "loss: 2.060966  [38400/60000]\n",
      "loss: 1.979399  [44800/60000]\n",
      "loss: 1.979185  [51200/60000]\n",
      "loss: 1.919121  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.915151 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.945351  [    0/60000]\n",
      "loss: 1.914565  [ 6400/60000]\n",
      "loss: 1.809794  [12800/60000]\n",
      "loss: 1.850881  [19200/60000]\n",
      "loss: 1.744500  [25600/60000]\n",
      "loss: 1.685743  [32000/60000]\n",
      "loss: 1.717401  [38400/60000]\n",
      "loss: 1.609574  [44800/60000]\n",
      "loss: 1.626242  [51200/60000]\n",
      "loss: 1.523578  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.537931 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.606289  [    0/60000]\n",
      "loss: 1.561545  [ 6400/60000]\n",
      "loss: 1.417892  [12800/60000]\n",
      "loss: 1.493660  [19200/60000]\n",
      "loss: 1.364803  [25600/60000]\n",
      "loss: 1.357039  [32000/60000]\n",
      "loss: 1.382238  [38400/60000]\n",
      "loss: 1.297515  [44800/60000]\n",
      "loss: 1.326642  [51200/60000]\n",
      "loss: 1.223179  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.252172 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.332218  [    0/60000]\n",
      "loss: 1.303099  [ 6400/60000]\n",
      "loss: 1.144621  [12800/60000]\n",
      "loss: 1.256509  [19200/60000]\n",
      "loss: 1.124458  [25600/60000]\n",
      "loss: 1.146963  [32000/60000]\n",
      "loss: 1.179208  [38400/60000]\n",
      "loss: 1.108248  [44800/60000]\n",
      "loss: 1.142742  [51200/60000]\n",
      "loss: 1.052048  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.080026 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Hyperparamètres\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Chargement des données\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Définition du modèle\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Définition de la loss function et de l'optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Calcul des prédictions et de la loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# Entraînement du modèle\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d74bc4-4156-4b59-af62-f34330d61886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
