{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad1cf62-9b63-4e71-aec7-e9aaeac65572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers, losses, optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conv_block(inputs, filters, dropout_rate=0.3):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet_model(input_shape=(256, 256, 3), num_classes=21):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder (Contracting Path)\n",
    "    c1 = conv_block(inputs, 64)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 128)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 256)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 512)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bridge\n",
    "    bridge = conv_block(p4, 1024)\n",
    "    \n",
    "    # Decoder (Expansive Path)\n",
    "    u1 = layers.UpSampling2D((2, 2))(bridge)\n",
    "    u1 = layers.concatenate([u1, c4])\n",
    "    c5 = conv_block(u1, 512)\n",
    "    \n",
    "    u2 = layers.UpSampling2D((2, 2))(c5)\n",
    "    u2 = layers.concatenate([u2, c3])\n",
    "    c6 = conv_block(u2, 256)\n",
    "    \n",
    "    u3 = layers.UpSampling2D((2, 2))(c6)\n",
    "    u3 = layers.concatenate([u3, c2])\n",
    "    c7 = conv_block(u3, 128)\n",
    "    \n",
    "    u4 = layers.UpSampling2D((2, 2))(c7)\n",
    "    u4 = layers.concatenate([u4, c1])\n",
    "    c8 = conv_block(u4, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(c8)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Compilation du modèle\n",
    "model = unet_model()\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19caae82-8e8b-468e-87cb-faeb0174febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGate(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.filters = filters\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w_g = layers.Conv2D(self.filters, 1, padding='same')\n",
    "        self.w_x = layers.Conv2D(self.filters, 1, padding='same')\n",
    "        self.psi = layers.Conv2D(1, 1, padding='same', activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        g, x = inputs\n",
    "        g1 = self.w_g(g)\n",
    "        x1 = self.w_x(x)\n",
    "        psi = tf.nn.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "def attention_unet(input_shape=(256, 256, 3), num_classes=21):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, 64)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 128)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 256)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 512)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bridge\n",
    "    bridge = conv_block(p4, 1024)\n",
    "    \n",
    "    # Decoder with Attention\n",
    "    u1 = layers.UpSampling2D((2, 2))(bridge)\n",
    "    att1 = AttentionGate(512)([u1, c4])\n",
    "    u1 = layers.concatenate([u1, att1])\n",
    "    c5 = conv_block(u1, 512)\n",
    "    \n",
    "    u2 = layers.UpSampling2D((2, 2))(c5)\n",
    "    att2 = AttentionGate(256)([u2, c3])\n",
    "    u2 = layers.concatenate([u2, att2])\n",
    "    c6 = conv_block(u2, 256)\n",
    "    \n",
    "    u3 = layers.UpSampling2D((2, 2))(c6)\n",
    "    att3 = AttentionGate(128)([u3, c2])\n",
    "    u3 = layers.concatenate([u3, att3])\n",
    "    c7 = conv_block(u3, 128)\n",
    "    \n",
    "    u4 = layers.UpSampling2D((2, 2))(c7)\n",
    "    att4 = AttentionGate(64)([u4, c1])\n",
    "    u4 = layers.concatenate([u4, att4])\n",
    "    c8 = conv_block(u4, 64)\n",
    "    \n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(c8)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7be2457-0a98-4ccc-a528-fe2239e4437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_unet(input_shape=(256, 256, 3), num_classes=21):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Utiliser les couches spécifiques pour les skip connections\n",
    "    layer_names = [\n",
    "        'conv1_relu',          # 64 filters\n",
    "        'conv2_block3_out',    # 256 filters\n",
    "        'conv3_block4_out',    # 512 filters\n",
    "        'conv4_block6_out',    # 1024 filters\n",
    "    ]\n",
    "    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "    \n",
    "    # Create feature extraction model\n",
    "    encoder = Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "    encoder.trainable = False  # Transfer learning\n",
    "    \n",
    "    # Decoder\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    \n",
    "    # Reverse features for decoder\n",
    "    f1, f2, f3, f4 = features\n",
    "    \n",
    "    # Decoder with skip connections\n",
    "    x = layers.Conv2DTranspose(512, 3, strides=2, padding='same')(f4)\n",
    "    x = layers.concatenate([x, f3])\n",
    "    x = conv_block(x, 512)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.concatenate([x, f2])\n",
    "    x = conv_block(x, 256)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.concatenate([x, f1])\n",
    "    x = conv_block(x, 128)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same')(x)\n",
    "    x = conv_block(x, 64)\n",
    "    \n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01df3d4-75f3-4dbe-bfec-f5146cd14efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeplabv3_plus(input_shape=(512, 512, 3), num_classes=21, output_stride=16):\n",
    "    # Backbone Xception\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Atrous Spatial Pyramid Pooling\n",
    "    def aspp_block(inputs, filters=256):\n",
    "        # Different dilation rates\n",
    "        conv1 = layers.Conv2D(filters, 1, padding='same')(inputs)\n",
    "        conv2 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6)(inputs)\n",
    "        conv3 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12)(inputs)\n",
    "        conv4 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18)(inputs)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        gap = layers.GlobalAveragePooling2D()(inputs)\n",
    "        gap = layers.Reshape((1, 1, filters))(gap)\n",
    "        gap = layers.Conv2D(filters, 1, padding='same')(gap)\n",
    "        gap = layers.UpSampling2D(size=(input_shape[0]//output_stride, \n",
    "                                       input_shape[1]//output_stride))(gap)\n",
    "        \n",
    "        # Concatenate all branches\n",
    "        return layers.concatenate([conv1, conv2, conv3, conv4, gap])\n",
    "    \n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    \n",
    "    # ASPP\n",
    "    aspp = aspp_block(x)\n",
    "    aspp = layers.Conv2D(256, 1, padding='same')(aspp)\n",
    "    aspp = layers.BatchNormalization()(aspp)\n",
    "    aspp = layers.Activation('relu')(aspp)\n",
    "    \n",
    "    # Decoder\n",
    "    decoder = layers.UpSampling2D((4, 4))(aspp)\n",
    "    decoder = layers.concatenate([decoder, base_model.get_layer('block13_sepconv2_bn').output])\n",
    "    decoder = layers.Conv2D(256, 3, padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    \n",
    "    decoder = layers.UpSampling2D((4, 4))(decoder)\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(decoder)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f536a67-6343-4433-b6ac-c6f593393ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, img_shape=(64, 64, 3), latent_dim=100):\n",
    "        self.img_shape = img_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build models\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        \n",
    "        # Compile discriminator\n",
    "        self.discriminator.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=optimizers.Adam(0.0002, 0.5),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Combined model\n",
    "        z = layers.Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        validity = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=optimizers.Adam(0.0002, 0.5)\n",
    "        )\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(8*8*256, input_dim=self.latent_dim),\n",
    "            layers.Reshape((8, 8, 256)),\n",
    "            layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Conv2D(3, 3, padding='same', activation='tanh')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, 3, strides=2, input_shape=self.img_shape, padding='same'),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Conv2D(64, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Conv2D(128, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Conv2D(256, 3, strides=1, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(0.2),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a0431e-a2bc-4f14-b817-e2a7162556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.gamma = self.add_weight(shape=[1], initializer='zeros')\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.query = layers.Conv2D(self.filters//8, 1)\n",
    "        self.key = layers.Conv2D(self.filters//8, 1)\n",
    "        self.value = layers.Conv2D(self.filters, 1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        batch_size, h, w, c = x.shape\n",
    "        \n",
    "        # Query, Key, Value\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        # Reshape for matrix multiplication\n",
    "        q = tf.reshape(q, [batch_size, h*w, -1])\n",
    "        k = tf.reshape(k, [batch_size, h*w, -1])\n",
    "        v = tf.reshape(v, [batch_size, h*w, -1])\n",
    "        \n",
    "        \n",
    "        # Attention scores\n",
    "        attention = tf.matmul(q, k, transpose_b=True)\n",
    "        attention = tf.nn.softmax(attention, axis=-1)\n",
    "        \n",
    "        # Weighted sum\n",
    "        out = tf.matmul(attention, v)\n",
    "        out = tf.reshape(out, [batch_size, h, w, -1])\n",
    "        \n",
    "        return self.gamma * out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea631645-678b-4147-a246-e90fefdf34c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
